
% % Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{albalak-etal-2022-feta,
    title = "{FETA}: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue",
    author = "Albalak, Alon  and
        Tuan, Yi-Lin  and
        Jandaghi, Pegah  and
        Pryor, Connor  and
        Yoffe, Luke  and
        Ramachandran, Deepak  and
        Getoor, Lise  and
        Pujara, Jay  and
        Wang, William Yang",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.751",
    pages = "10936--10953",
    abstract = "Task transfer, transferring knowledge contained in related tasks, holds the promise of reducing the quantity of labeled data required to fine-tune language models. Dialogue understanding encompasses many diverse tasks, yet task transfer has not been thoroughly studied in conversational AI. This work explores conversational task transfer by introducing FETA: a benchmark for FEw-sample TAsk transfer in open-domain dialogue.FETA contains two underlying sets of conversations upon which there are 10 and 7 tasks annotated, enabling the study of intra-dataset task transfer; task transfer without domain adaptation. We utilize three popular language models and three learning algorithms to analyze the transferability between 132 source-target task pairs and create a baseline for future work.We run experiments in the single- and multi-source settings and report valuable findings, e.g., most performance trends are model-specific, and span extraction and multiple-choice tasks benefit the most from task transfer.In addition to task transfer, FETA can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning.",
}

@inproceedings{chen2016character,
  title={Character identification on multiparty conversation: Identifying mentions of characters in tv shows},
  author={Chen, Yu-Hsin and Choi, Jinho D},
  booktitle={Proceedings of the 17th annual meeting of the special interest group on discourse and dialogue},
  pages={90--100},
  year={2016}
}

@article{zahiri2017emotion,
  title={Emotion detection on tv show transcripts with sequence-based convolutional neural networks},
  author={Zahiri, Sayyed M and Choi, Jinho D},
  journal={arXiv preprint arXiv:1708.04299},
  year={2017}
}

@inproceedings{jiang2020automatic,
  title={Automatic text-based personality recognition on monologues and multiparty dialogues using attentive networks and contextual embeddings (student abstract)},
  author={Jiang, Hang and Zhang, Xianzhe and Choi, Jinho D},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={10},
  pages={13821--13822},
  year={2020}
}